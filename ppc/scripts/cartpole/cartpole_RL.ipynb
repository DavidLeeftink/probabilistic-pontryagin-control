{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "one_level_up_dir = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "sys.path.append(one_level_up_dir)\n",
    "import jax._src.random as prng\n",
    "import jax\n",
    "from jax import config, jit\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import diffrax as dfx\n",
    "import matplotlib.pyplot as plt\n",
    "import optax as ox\n",
    "import equinox as eqx\n",
    "from gpdx.systems.nonlinear_dynamics import VanDerPol\n",
    "from gpdx.control.trajectory_optimizers import *\n",
    "from gpdx.control.cost_functions import QuadraticCost\n",
    "from gpdx.control.mpc import *\n",
    "# from gpdx.dataset import DiffEqDataset\n",
    "from gpdx.nn.node import NeuralODE, EnsembleNeuralODE\n",
    "from gpdx.nn.nnvectorfield import NeuralVectorField, EnsembleNeuralVectorField\n",
    "from gpdx.control.mpc import ensembleIndirectMPC\n",
    "from gpdx.control.trajectory_optimizers import EnsemblePMPForward\n",
    "\n",
    "from gpdx.fit import *\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "config.update(\"jax_debug_nans\", True)\n",
    "PRNGKey = prng.KeyArray\n",
    "key = jr.PRNGKey(1239) \n",
    "key, subkey = jr.split(key)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define control problem and generate data to train NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpdx.control.control_task import CartPoleTask\n",
    "env = CartPoleTask()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data generation\n",
    "num_trials = 1 # RL trials\n",
    "t0 = env.t0\n",
    "tf = env.tf\n",
    "dt = env.Delta_t\n",
    "dt0_dense = 5e-3 # \n",
    "\n",
    "num_initial_trials = 250 # initial dataset - note that this is of 1 sec, so really this is 50 trials.\n",
    "num_obs = int((tf-t0)/dt)\n",
    "D_in, D_out = env.D_sys+ env.D_control, env.D_sys\n",
    "noise = jnp.array([jnp.sqrt(env.measurement_noise_std) for _ in range(D_out)]) # sigma^2 = 0.05 in Hegde experiment 4.1\n",
    "\n",
    "## ode params\n",
    "stepsize_controller=dfx.PIDController(rtol=1e-4, atol=1e-5, jump_ts=None)\n",
    "internal_solver = dfx.Dopri5() \n",
    "dt0_internal = 0.025\n",
    "\n",
    "## neural network\n",
    "ensemble_size = 5\n",
    "data_per_ensemble = num_initial_trials\n",
    "hidden_dim = 32\n",
    "layer_sizes = (D_in, hidden_dim, hidden_dim, D_out)\n",
    "activation = jax.nn.elu\n",
    "\n",
    "## training\n",
    "num_iters = 3_500\n",
    "init_obs_noise = 0.5\n",
    "batch_size = -1 # -1 or num_trials for no batching\n",
    "lr = 0.0015\n",
    "log_rate = 20\n",
    "\n",
    "# MPC \n",
    "maxiter = 25\n",
    "H = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jr.uniform(key, (env.D_sys,), minval=jnp.array([-1, -3, -5, -5]), maxval=jnp.array([2, 9, 5, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial state distribution\n",
    "real_system = env.real_system\n",
    "key, subkey = jr.split(key)\n",
    "\n",
    "# randomly sample observation times. \n",
    "## split trials in segments of 1 second.\n",
    "tf = 1.\n",
    "num_obs = int((tf-t0)/dt)\n",
    "\n",
    "ts_uniform = jnp.concatenate([jnp.linspace(t0, tf-env.Delta_t, num_obs)[None] for _ in range(num_initial_trials)], axis=0)\n",
    "ts = jnp.sort(ts_uniform, axis=1)\n",
    "ts_dense = jnp.concatenate([jnp.linspace(env.t0, tf, int( ((1/dt0_dense))*(tf-t0)))[None] for _ in range(num_initial_trials)], axis=0)\n",
    "freqs = jnp.arange(1,num_initial_trials+1)\n",
    "indices = jnp.linspace(0.2, 1.5, num_initial_trials)\n",
    "\n",
    "print(key)\n",
    "us = jr.uniform(key=key, shape=(num_initial_trials, ts_dense.shape[-1]),minval=env.lb, maxval=env.ub)[...,None]\n",
    "key, subkey = jr.split(key, 2)\n",
    "\n",
    "# us = jax.vmap(lambda t, i: 1.3*jnp.cos(3*jr.uniform(key(round(2*i+3**i)))+17.5*jr.uniform(key)*jnp.pi*t*i+jr.normal(key)), in_axes=(0,0))(ts_dense, indices)[..., None]\n",
    "\n",
    "# us = jax.vmap(lambda t, i: 1.3*jnp.cos(3*jr.uniform(key(round(2*i+3**i)))+17.5*jr.uniform(key)*jnp.pi*t*i+jr.normal(key))+\n",
    "#               2.5*jnp.cos(6.5*jr.uniform(key*jnp.pi*t*i+4*jr.normal(key))), in_axes=(0,0))(ts_dense, indices)[..., None]\n",
    "\n",
    "\n",
    "key, subkey = jr.split(key)\n",
    "get_initial_condition = lambda key: env.get_initial_condition(key) + jr.uniform(key, (env.D_sys,), minval=jnp.array([-1, -1, -5, -5]), maxval=jnp.array([3.5, 4, 5, 4]))\n",
    "\n",
    "# simulate data from real system\n",
    "key, subkey = jr.split(key)\n",
    "data, true_y0s = env.real_system.generate_synthetic_data(subkey,\n",
    "                                           num_initial_trials,\n",
    "                                           dt0=dt0_dense,\n",
    "                                           ts=ts,\n",
    "                                           us=us,\n",
    "                                           obs_stddev=noise,\n",
    "                                           ts_dense=ts_dense,\n",
    "                                           x0_distribution=get_initial_condition,\n",
    "                                           standardize_at_initialisation=False,\n",
    "                                          )\n",
    "data.__post_init__()\n",
    "\n",
    "tf = env.tf\n",
    "num_obs = int((tf-t0)/dt)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.x_star)\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ys_full_scale = data.ys#data.inverse_standardize(data.ys)\n",
    "for i in range(data.ts.shape[0]):\n",
    "    plt.plot(data.ts[i], ys_full_scale[i,:,0])\n",
    "    plt.plot(data.ts[i], ys_full_scale[i,:,1])\n",
    "plt.ylabel('x')\n",
    "plt.xlabel('t')\n",
    "# ax.scatter(env.x_star[0], env.x_star[1], color='gold')#, env.x_star[2])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('phase plane (x and theta)')\n",
    "for i in range(data.ts.shape[0]):\n",
    "    plt.plot(ys_full_scale[i,:,1], ys_full_scale[i,:,3])\n",
    "ax.scatter(env.x_star[0], env.x_star[1], color='gold')\n",
    "plt.show()\n",
    "\n",
    "us_full_scale = data.us#data.inverse_standardize_us(data.us) \n",
    "plt.figure()\n",
    "plt.title('u(t)')\n",
    "for i in range(30):\n",
    "    plt.plot(data.ts_dense[i], us_full_scale[i,:,0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ys.shape, data.ts.shape, data.us.shape, data.ts_dense.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train neural ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpdx.nn.nnvectorfield import EnsembleNeuralVectorField\n",
    "from gpdx.nn.node import EnsembleNeuralODE\n",
    "from gpdx.fit import fit_node\n",
    "from gpdx.nn.node import mse_loss_ensemble\n",
    "\n",
    "\n",
    "def train_network(data, key, num_iters):\n",
    "    key, subkey = jr.split(key)\n",
    "    keys = jr.split(subkey, ensemble_size)\n",
    "\n",
    "\n",
    "    ensemble_datasets = jax.vmap(get_batch, in_axes=(None, None, 0, None))(data, data.n, keys, False)\n",
    "    print(ensemble_datasets.n, ensemble_datasets.ys.shape)\n",
    "    key, subkey = jr.split(key)\n",
    "\n",
    "    ensemble_vectorfield = EnsembleNeuralVectorField(\n",
    "                                ensemble_size=ensemble_size,\n",
    "                                layer_sizes=layer_sizes,\n",
    "                                activation=activation,\n",
    "                                D_sys=real_system.D_sys,\n",
    "                                D_control=real_system.D_control,\n",
    "                                key=key,)\n",
    "\n",
    "    \"\"\" testing the neural ODE call with the newly created vectorfield class.\"\"\"\n",
    "\n",
    "    # initialize p(x0)\n",
    "    x0_mean_init = ensemble_datasets.ys[:,:,0,:]\n",
    "    x0_diag_raw = jnp.zeros_like(x0_mean_init)-1.\n",
    "\n",
    "    ensemble_node = EnsembleNeuralODE(\n",
    "                            ensemble_size=ensemble_size,\n",
    "                            obs_noise_raw=jnp.log(jnp.exp(init_obs_noise)-1.),\n",
    "                            x0_mean=x0_mean_init-1,\n",
    "                            x0_diag_raw=x0_diag_raw,\n",
    "                            vectorfield=ensemble_vectorfield,\n",
    "                            solver=dfx.Dopri5(),\n",
    "                            dt0=dt0_internal,\n",
    "                            stepsize_controller=dfx.ConstantStepSize(),#dfx.PIDController(rtol=1e-3,atol=1e-5),\n",
    "                            D_sys=real_system.D_sys,\n",
    "                            D_control=real_system.D_control,\n",
    "                            )\n",
    "\n",
    "    optim = ox.adam(learning_rate=lr)\n",
    "\n",
    "    opt_ensemble_node, history = fit_node(model=ensemble_node, \n",
    "            objective=mse_loss_ensemble, \n",
    "            train_data=ensemble_datasets, \n",
    "            optim = optim, \n",
    "            key=subkey,\n",
    "            num_iters=num_iters,\n",
    "            batch_size=batch_size,\n",
    "            log_rate=log_rate,)\n",
    "    key, subkey = jr.split(key, 2)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(history)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Ensemble MSE')\n",
    "    plt.title(f'Final loss: {history[-1]}')\n",
    "    plt.show()\n",
    "\n",
    "    return opt_ensemble_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_trial(opt_ensemble_node, key:jr.PRNGKey, data:DiffEqDataset):\n",
    "\n",
    "        key, subkey = jr.split(key)        \n",
    "        n_segments = 2\n",
    "        print(f'Running PMP with {n_segments} segments')\n",
    "        us_init = jnp.arange(0, H, env.Delta_t) # only used for getting the shape for MPC vector - PMP doesnt requrie this.\n",
    "        pmp_solver = EnsemblePMPForward(f=opt_ensemble_node.vectorfield,\n",
    "                                D_sys=real_system.D_sys, \n",
    "                                D_control=real_system.D_control,\n",
    "                                ensemble_size=ensemble_size,\n",
    "                                n_segments=n_segments,\n",
    "                                state_cost=env.state_cost,\n",
    "                                termination_cost=env.termination_cost,\n",
    "                                maxiter=maxiter, \n",
    "                                lb=env.lb*jnp.ones((us_init.shape[0], real_system.D_control)),  ## To do: scale thios with the u standardization!\n",
    "                                ub=env.ub*jnp.ones((us_init.shape[0], real_system.D_control)),\n",
    "                                # standardize_x=data.standardize,\n",
    "                                # inverse_standardize_x=data.inverse_standardize,\n",
    "                                # standardize_u=data.standardize_us,\n",
    "                                # inverse_standardize_u=data.inverse_standardize_us,\n",
    "                                # sigma_x = data._original_ys_std,\n",
    "                                # sigma_u = data._original_us_std,\n",
    "                                )\n",
    "\n",
    "\n",
    "        ensemble_indirect_mpc = ensembleIndirectMPC(traj_optimizer=pmp_solver,\n",
    "                real_system=real_system,\n",
    "                internal_system=opt_ensemble_node,\n",
    "                state_cost=env.state_cost,\n",
    "                termination_cost=env.termination_cost,\n",
    "                verbose=True,\n",
    "                )\n",
    "        trial_ts = jnp.linspace(env.t0, env.tf, int( ((1/env.Delta_t))*(env.tf-env.t0))) #new_trial_dataset.ts\n",
    "\n",
    "        ts, ts_dense, X, Y, U, R = ensemble_indirect_mpc.simulate(\n",
    "                        x0=env.get_initial_condition(subkey), \n",
    "                        ts=trial_ts,\n",
    "                        Delta_t=env.Delta_t,\n",
    "                        x_star=env.x_star,\n",
    "                        dt0_internal=dt0_internal,\n",
    "                        dt0_dense=dt0_dense,\n",
    "                        H=H,\n",
    "                        obs_noise=0.,\n",
    "                        key=subkey,\n",
    "                        # standardize_x=data.standardize,\n",
    "                        # inverse_standardize_x=data.inverse_standardize,\n",
    "                        # standardize_u=data.standardize_us,\n",
    "                        # inverse_standardize_u=data.inverse_standardize_us,\n",
    "                    )\n",
    "        key, subkey = jr.split(key)\n",
    "\n",
    "\n",
    "        pmp_ensemble_trial_cost = R[-1]\n",
    "        plt.plot(ts_dense, R)\n",
    "        plt.title(f'Indirect approach with NODE: Integrated Cost: {pmp_ensemble_trial_cost}')\n",
    "        plt.ylabel('Cost ')\n",
    "        plt.xlabel('t')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        # visualize \n",
    "        labels = [r'$x$', r'$\\theta$', r'$\\dot{x}$', r'$\\dot{\\theta}$']\n",
    "        for i in range(X.shape[-1]):\n",
    "                dim_color = f'C{i*2}'\n",
    "                plt.plot(ts_dense, X[:,i], label=labels[i], color=dim_color)\n",
    "\n",
    "        plt.axhline(y=env.x_star[0], color='C0', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[1], color='C2', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[2], color='C4', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[3], color='C4', linestyle=':')\n",
    "        plt.title(f'Integrated Cost: {R[-1]}')\n",
    "        plt.ylabel('x')\n",
    "        plt.xlabel('t')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        return ts, ts_dense, X, Y, U, R\n",
    "\n",
    "def run_single_trial_meanHamiltonian(opt_ensemble_node, key:jr.PRNGKey, data:DiffEqDataset):\n",
    "\n",
    "        key, subkey = jr.split(key)        \n",
    "        n_segments = 2\n",
    "        print(f'Running PMP with {n_segments} segments')\n",
    "        us_init = jnp.arange(0, H, env.Delta_t) # only used for getting the shape for MPC vector - PMP doesnt requrie this.\n",
    "        pmp_solver = EnsemblePMPForwardMeanHamiltonian(f=opt_ensemble_node.vectorfield,\n",
    "                                D_sys=real_system.D_sys, \n",
    "                                D_control=real_system.D_control,\n",
    "                                ensemble_size=ensemble_size,\n",
    "                                n_segments=n_segments,\n",
    "                                state_cost=env.state_cost,\n",
    "                                termination_cost=env.termination_cost,\n",
    "                                maxiter=maxiter, \n",
    "                                lb=env.lb*jnp.ones((us_init.shape[0], real_system.D_control)),  ## To do: scale thios with the u standardization!\n",
    "                                ub=env.ub*jnp.ones((us_init.shape[0], real_system.D_control)),\n",
    "                                # standardize_x=data.standardize,\n",
    "                                # inverse_standardize_x=data.inverse_standardize,\n",
    "                                # standardize_u=data.standardize_us,\n",
    "                                # inverse_standardize_u=data.inverse_standardize_us,\n",
    "                                # sigma_x = data._original_ys_std,\n",
    "                                # sigma_u = data._original_us_std,\n",
    "                                )\n",
    "\n",
    "\n",
    "        ensemble_indirect_mpc = ensembleIndirectMPC(traj_optimizer=pmp_solver,\n",
    "                real_system=real_system,\n",
    "                internal_system=opt_ensemble_node,\n",
    "                state_cost=env.state_cost,\n",
    "                termination_cost=env.termination_cost,\n",
    "                verbose=True,\n",
    "                )\n",
    "        trial_ts = jnp.linspace(env.t0, env.tf, int( ((1/env.Delta_t))*(env.tf-env.t0))) #new_trial_dataset.ts\n",
    "\n",
    "        ts, ts_dense, X, Y, U, R = ensemble_indirect_mpc.simulate(\n",
    "                        x0=env.get_initial_condition(subkey), \n",
    "                        ts=trial_ts,\n",
    "                        Delta_t=env.Delta_t,\n",
    "                        x_star=env.x_star,\n",
    "                        dt0_internal=dt0_internal,\n",
    "                        dt0_dense=dt0_dense,\n",
    "                        H=H,\n",
    "                        obs_noise=0.,\n",
    "                        key=subkey,\n",
    "                        # standardize_x=data.standardize,\n",
    "                        # inverse_standardize_x=data.inverse_standardize,\n",
    "                        # standardize_u=data.standardize_us,\n",
    "                        # inverse_standardize_u=data.inverse_standardize_us,\n",
    "                    )\n",
    "        key, subkey = jr.split(key)\n",
    "\n",
    "\n",
    "        pmp_ensemble_trial_cost = R[-1]\n",
    "        plt.plot(ts_dense, R)\n",
    "        plt.title(f'Indirect approach with NODE: Integrated Cost: {pmp_ensemble_trial_cost}')\n",
    "        plt.ylabel('Cost ')\n",
    "        plt.xlabel('t')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        # visualize \n",
    "        labels = [r'$x$', r'$\\theta$', r'$\\dot{x}$', r'$\\dot{\\theta}$']\n",
    "        for i in range(X.shape[-1]):\n",
    "                dim_color = f'C{i*2}'\n",
    "                plt.plot(ts_dense, X[:,i], label=labels[i], color=dim_color)\n",
    "\n",
    "        plt.axhline(y=env.x_star[0], color='C0', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[1], color='C2', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[2], color='C4', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[3], color='C4', linestyle=':')\n",
    "        plt.title(f'Integrated Cost: {R[-1]}')\n",
    "        plt.ylabel('x')\n",
    "        plt.xlabel('t')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        return ts, ts_dense, X, Y, U, R\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset:DiffEqDataset, timepoints_per_split:int):\n",
    "    \"\"\"\n",
    "        Take a single trajectory dataset, and split it into N trajectories of length T_n. \n",
    "        This assumes the timepoints_per_split argument is correct for N. \n",
    "    \"\"\"\n",
    "    ys, us, ts, ts_dense = dataset.ys[0], dataset.us[0], dataset.ts[0], dataset.ts_dense[0]\n",
    "    num_new_datasets = int(ts.shape[0]/timepoints_per_split)\n",
    "    dense_timepoints_per_split = int(timepoints_per_split * (dataset.ts_dense[0].shape[0]/dataset.ts[0].shape[0]))\n",
    "    new_dataset = None\n",
    "    for n in range(num_new_datasets):\n",
    "        ys_n = ys[n*timepoints_per_split:((n+1)*timepoints_per_split)][None]\n",
    "        us_n = us[n*dense_timepoints_per_split:((n+1)*dense_timepoints_per_split)][None]\n",
    "        ts_n = ts[n*timepoints_per_split:((n+1)*timepoints_per_split)][None]\n",
    "        ts_dense_n =ts_dense[n*dense_timepoints_per_split:((n+1)*dense_timepoints_per_split)][None]\n",
    "        data_n = DiffEqDataset(ys=ys_n, us=us_n, ts=ts_n, ts_dense=ts_dense_n, standardize_at_initialisation=False)\n",
    "        if new_dataset is None:\n",
    "            new_dataset = data_n\n",
    "        else:\n",
    "            new_dataset = new_dataset + data_n\n",
    "\n",
    "    return new_dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run RL trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ts.shape, data.us.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_costs = []\n",
    "for i in range(num_trials):\n",
    "    print(f'Starting trial {i+1}/{num_trials}')\n",
    "\n",
    "    # train deep NODE ensemble \n",
    "    key, subkey = jr.split(key)\n",
    "    opt_ensemble_node = train_network(data, subkey, num_iters = num_iters)#num_iters + 200*i)\n",
    "\n",
    "    # run trial\n",
    "    # key, subkey = jr.split(key)\n",
    "    # ts, ts_dense, X, Y, U, R = run_single_trial(opt_ensemble_node=opt_ensemble_node, key=subkey, data=data)\n",
    "    # trial_costs.append(R[-1])\n",
    "\n",
    "    # augment dataset\n",
    "    # new_trial_dataset = DiffEqDataset(ts[None,...], Y[None,...], U[None,...], ts_dense=ts_dense[None,...], standardize_at_initialisation=True)\n",
    "    # new_trial_dataset.__post_init__()\n",
    "\n",
    "    # # split into multiple shorter trajectories.\n",
    "    # new_trial_datasets = split_dataset(new_trial_dataset, 40)\n",
    "    # new_trial_datasets.__post_init__()\n",
    "    \n",
    "    # # add with previous data.\n",
    "    # data = data + new_trial_datasets\n",
    "    # data.__post_init__()\n",
    "\n",
    "    \n",
    "trial_costs = jnp.array(trial_costs)\n",
    "plt.figure()\n",
    "plt.title('Costs over time')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Cost')\n",
    "plt.plot(jnp.arange(trial_costs.shape[0]), trial_costs)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.standardize_us(jnp.zeros((2,1))), data._original_us_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.ys.shape, data.us.shape, new_trial_dataset.us.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(new_trial_datasets.ys.shape, new_trial_datasets.ts.shape, new_trial_datasets.us.shape, new_trial_datasets.ts_dense.shape)\n",
    "# data.ys.shape, data.ts.shape, data.us.shape, data.ts_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_trial_sqp(opt_ensemble_node, key:jr.PRNGKey):\n",
    "\n",
    "        key, subkey = jr.split(key)        \n",
    "        \n",
    "        us_init = jnp.zeros((jnp.arange(0, H, env.Delta_t).shape[0], env.D_control))\n",
    "   \n",
    "        adam_solver = SLSQP(\n",
    "                # step_size=0.05,\n",
    "                lb=env.lb*jnp.ones_like(us_init),\n",
    "                ub=env.ub*jnp.ones_like(us_init),\n",
    "                maxiter=maxiter,)\n",
    "        \n",
    "        ensemble_direct_mpc = ensembleDirectMPC(\n",
    "                traj_optimizer=adam_solver,\n",
    "                real_system=env.real_system,\n",
    "                internal_system=opt_ensemble_node,\n",
    "                state_cost=env.state_cost,\n",
    "                termination_cost=env.termination_cost,\n",
    "                verbose=True,\n",
    "                )\n",
    "        trial_ts = jnp.linspace(env.t0, env.tf, int( ((1/env.Delta_t))*(env.tf-env.t0))) #new_trial_dataset.ts\n",
    "\n",
    "\n",
    "        ts, ts_dense, X, Y, U, R = ensemble_direct_mpc.simulate(x0=env.get_initial_condition(),\n",
    "                ts=trial_ts,\n",
    "                Delta_t=env.Delta_t,\n",
    "                dt0_dense=dt0_dense,\n",
    "                x_star=env.x_star,\n",
    "                H=H, \n",
    "                )\n",
    "\n",
    "\n",
    "        pmp_ensemble_trial_cost = R[-1]\n",
    "        plt.plot(ts_dense, R)\n",
    "        plt.title(f'SQP: Direct approach with NODE: Integrated Cost: {pmp_ensemble_trial_cost}')\n",
    "        plt.ylabel('Cost ')\n",
    "        plt.xlabel('t')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        # visualize \n",
    "        labels = [r'$x$', r'$\\theta$', r'$\\dot{x}$', r'$\\dot{\\theta}$']\n",
    "        for i in range(X.shape[-1]):\n",
    "                dim_color = f'C{i*2}'\n",
    "                plt.plot(ts_dense, X[:,i], label=labels[i], color=dim_color)\n",
    "\n",
    "        plt.axhline(y=env.x_star[0], color='C0', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[1], color='C2', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[2], color='C4', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[3], color='C4', linestyle=':')\n",
    "        plt.title(f'Integrated Cost: {R[-1]}')\n",
    "        plt.ylabel('x')\n",
    "        plt.xlabel('t')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        return ts, ts_dense, X, Y, U, R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_trial_bfgs(opt_ensemble_node, key:jr.PRNGKey):\n",
    "\n",
    "        key, subkey = jr.split(key)        \n",
    "  \n",
    "        us_init = jnp.zeros((jnp.arange(0, H, env.Delta_t).shape[0], env.D_control))\n",
    "   \n",
    "        bfgs_solver = LBFGSB(\n",
    "                # step_size=0.05,\n",
    "                lb=env.lb*jnp.ones_like(us_init),\n",
    "                ub=env.ub*jnp.ones_like(us_init),\n",
    "                maxiter=maxiter,)\n",
    "        \n",
    "        ensemble_direct_mpc = ensembleDirectMPC(\n",
    "                traj_optimizer=bfgs_solver,\n",
    "                real_system=env.real_system,\n",
    "                internal_system=opt_ensemble_node,\n",
    "                state_cost=env.state_cost,\n",
    "                termination_cost=env.termination_cost,\n",
    "                verbose=True,\n",
    "                )\n",
    "        trial_ts = jnp.linspace(env.t0, env.tf, int( ((1/env.Delta_t))*(env.tf-env.t0))) #new_trial_dataset.ts\n",
    "\n",
    "\n",
    "        ts, ts_dense, X, Y, U, R = ensemble_direct_mpc.simulate(x0=env.get_initial_condition(),\n",
    "                ts=trial_ts,\n",
    "                Delta_t=env.Delta_t,\n",
    "                dt0_dense=dt0_dense,\n",
    "                x_star=env.x_star,\n",
    "                H=H, \n",
    "                )\n",
    "\n",
    "\n",
    "        pmp_ensemble_trial_cost = R[-1]\n",
    "        plt.plot(ts_dense, R)\n",
    "        plt.title(f'BFGS: Direct approach with NODE: Integrated Cost: {pmp_ensemble_trial_cost}')\n",
    "        plt.ylabel('Cost ')\n",
    "        plt.xlabel('t')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        # visualize \n",
    "        labels = [r'$x$', r'$\\theta$', r'$\\dot{x}$', r'$\\dot{\\theta}$']\n",
    "        for i in range(X.shape[-1]):\n",
    "                dim_color = f'C{i*2}'\n",
    "                plt.plot(ts_dense, X[:,i], label=labels[i], color=dim_color)\n",
    "\n",
    "        plt.axhline(y=env.x_star[0], color='C0', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[1], color='C2', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[2], color='C4', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[3], color='C4', linestyle=':')\n",
    "        plt.title(f'Integrated Cost: {R[-1]}')\n",
    "        plt.ylabel('x')\n",
    "        plt.xlabel('t')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        return ts, ts_dense, X, Y, U, R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_trial_cem(opt_ensemble_node, key:jr.PRNGKey):\n",
    "\n",
    "        key, subkey = jr.split(key)        \n",
    "\n",
    "        us_init = jnp.zeros((jnp.arange(0, H, env.Delta_t).shape[0], env.D_control))\n",
    "        cem_solver = iCEM(\n",
    "                pop_size=700,\n",
    "                elite_size=int(0.13*700),\n",
    "                # alpha=0.3,\n",
    "                # step_size=0.1,\n",
    "                beta=1,\n",
    "                lb=env.lb*jnp.ones_like(us_init),\n",
    "                ub=env.ub*jnp.ones_like(us_init),\n",
    "                maxiter=maxiter,)\n",
    "        \n",
    "        ensemble_direct_mpc = ensembleDirectMPC(\n",
    "                traj_optimizer=cem_solver,\n",
    "                real_system=env.real_system,\n",
    "                internal_system=opt_ensemble_node,\n",
    "                state_cost=env.state_cost,\n",
    "                termination_cost=env.termination_cost,\n",
    "                verbose=True,\n",
    "                )\n",
    "        trial_ts = jnp.linspace(env.t0, env.tf, int( ((1/env.Delta_t))*(env.tf-env.t0))) #new_trial_dataset.ts\n",
    "\n",
    "\n",
    "        ts, ts_dense, X, Y, U, R = ensemble_direct_mpc.simulate(x0=env.get_initial_condition(),\n",
    "                ts=trial_ts,\n",
    "                Delta_t=env.Delta_t,\n",
    "                dt0_dense=dt0_dense,\n",
    "                x_star=env.x_star,\n",
    "                H=H, \n",
    "                )\n",
    "\n",
    "\n",
    "        pmp_ensemble_trial_cost = R[-1]\n",
    "        plt.plot(ts_dense, R)\n",
    "        plt.title(f'CEM: direct approach with NODE: Integrated Cost: {pmp_ensemble_trial_cost}')\n",
    "        plt.ylabel('Cost ')\n",
    "        plt.xlabel('t')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        # visualize \n",
    "        labels = [r'$x$', r'$\\theta$', r'$\\dot{x}$', r'$\\dot{\\theta}$']\n",
    "        for i in range(X.shape[-1]):\n",
    "                dim_color = f'C{i*2}'\n",
    "                plt.plot(ts_dense, X[:,i], label=labels[i], color=dim_color)\n",
    "\n",
    "        plt.axhline(y=env.x_star[0], color='C0', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[1], color='C2', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[2], color='C4', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[3], color='C4', linestyle=':')\n",
    "        plt.title(f'Integrated Cost: {R[-1]}')\n",
    "        plt.ylabel('x')\n",
    "        plt.xlabel('t')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        return ts, ts_dense, X, Y, U, R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single_trial_adam\u001b[39m(opt_ensemble_node, key:jr\u001b[39m.\u001b[39mPRNGKey):\n\u001b[1;32m      3\u001b[0m         key, subkey \u001b[39m=\u001b[39m jr\u001b[39m.\u001b[39msplit(key)        \n\u001b[1;32m      4\u001b[0m         us_init \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mzeros((jnp\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, H, env\u001b[39m.\u001b[39mDelta_t)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], env\u001b[39m.\u001b[39mD_control))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jr' is not defined"
     ]
    }
   ],
   "source": [
    "def run_single_trial_adam(opt_ensemble_node, key:jr.PRNGKey):\n",
    "\n",
    "        key, subkey = jr.split(key)        \n",
    "        us_init = jnp.zeros((jnp.arange(0, H, env.Delta_t).shape[0], env.D_control))\n",
    "        adam_solver = Adam(\n",
    "                step_size=0.01,\n",
    "                lb=env.lb*jnp.ones_like(us_init),\n",
    "                ub=env.ub*jnp.ones_like(us_init),\n",
    "                maxiter=maxiter,)\n",
    "        \n",
    "        ensemble_direct_mpc = ensembleDirectMPC(\n",
    "                traj_optimizer=adam_solver,\n",
    "                real_system=env.real_system,\n",
    "                internal_system=opt_ensemble_node,\n",
    "                state_cost=env.state_cost,\n",
    "                termination_cost=env.termination_cost,\n",
    "                verbose=True,\n",
    "                )\n",
    "        trial_ts = jnp.linspace(env.t0, env.tf, int( ((1/env.Delta_t))*(env.tf-env.t0))) #new_trial_dataset.ts\n",
    "\n",
    "\n",
    "        ts, ts_dense, X, Y, U, R = ensemble_direct_mpc.simulate(x0=env.get_initial_condition(),\n",
    "                ts=trial_ts,\n",
    "                Delta_t=env.Delta_t,\n",
    "                dt0_dense=dt0_dense,\n",
    "                x_star=env.x_star,\n",
    "                H=H, \n",
    "                )\n",
    "\n",
    "\n",
    "        pmp_ensemble_trial_cost = R[-1]\n",
    "        plt.plot(ts_dense, R)\n",
    "        plt.title(f'Adam: direct approach with NODE: Integrated Cost: {pmp_ensemble_trial_cost}')\n",
    "        plt.ylabel('Cost ')\n",
    "        plt.xlabel('t')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        # visualize \n",
    "        labels = [r'$x$', r'$\\theta$', r'$\\dot{x}$', r'$\\dot{\\theta}$']\n",
    "        for i in range(X.shape[-1]):\n",
    "                dim_color = f'C{i*2}'\n",
    "                plt.plot(ts_dense, X[:,i], label=labels[i], color=dim_color)\n",
    "\n",
    "        plt.axhline(y=env.x_star[0], color='C0', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[1], color='C2', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[2], color='C4', linestyle=':')\n",
    "        plt.axhline(y=env.x_star[3], color='C4', linestyle=':')\n",
    "        plt.title(f'Integrated Cost: {R[-1]}')\n",
    "        plt.ylabel('x')\n",
    "        plt.xlabel('t')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        return ts, ts_dense, X, Y, U, R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subkey"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run_single_trial_meanHamiltonian(opt_ensemble_node=opt_ensemble_node, key=subkey, data=data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run_single_trial(opt_ensemble_node=opt_ensemble_node, key=subkey, data=data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CEM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run_single_trial_cem(opt_ensemble_node=opt_ensemble_node, key=subkey)#, data=data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run_single_trial_sqp(opt_ensemble_node=opt_ensemble_node, key=subkey)#, data=data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run_single_trial_adam(opt_ensemble_node=opt_ensemble_node, key=subkey)#, data=data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run_single_trial_bfgs(opt_ensemble_node=opt_ensemble_node, key=subkey)#, data=data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors\n",
    "Method 1: Blue (#1f77b4, a muted MATLAB-like blue).\n",
    "\n",
    "Method 2: Red (#d62728, a subdued red).\n",
    "\n",
    "Method 3: Green (#2ca02c, a soft green).\n",
    "alpha 0.2 for confidence intervals.\n",
    "\n",
    "\n",
    "##  Linwidth\n",
    "linewidth=1.5 o\n",
    "\n",
    "## background lines:\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Dummy data\n",
    "# trials = np.arange(1, 21)\n",
    "# methods = {\n",
    "#     \"Method 1\": np.exp(-trials/5) * 20 + np.random.normal(0, 5, (10, 20)),\n",
    "#     \"Method 2\": np.exp(-trials/4) * 20 + np.random.normal(0, 5, (10, 20)),\n",
    "#     \"Method 3\": np.exp(-trials/3) * 20 + np.random.normal(0, 5, (10, 20))\n",
    "# }\n",
    "# analytical_max = np.full(20, -5)  # Example baseline\n",
    "\n",
    "# # Colors\n",
    "# colors = [\"#1f77b4\", \"#d62728\", \"#2ca02c\"]\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# for i, (name, data) in enumerate(methods.items()):\n",
    "#     mean = data.mean(axis=0)\n",
    "#     std = data.std(axis=0)\n",
    "#     ci = 1.96 * std / np.sqrt(10)  # 95% CI\n",
    "#     plt.plot(trials, mean, label=name, color=colors[i], linewidth=1.5, alpha=0.8)\n",
    "#     plt.fill_between(trials, mean - ci, mean + ci, color=colors[i], alpha=0.2)\n",
    "\n",
    "# plt.plot(trials, analytical_max, \"--\", color=\"#7f7f7f\", label=\"True Model Minimum\")\n",
    "# plt.xlabel(\"Number of Trials\", fontsize=12)\n",
    "# plt.ylabel(\"Cost\", fontsize=12)\n",
    "# plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "# plt.legend(loc=\"upper right\", fontsize=10)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Save for IEEE\n",
    "# # plt.savefig(\"cartpole_cost.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# bar_width = 0.2\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# for i, (name, costs) in enumerate(methods.items()):\n",
    "#     mean = costs.mean(axis=0)\n",
    "#     std = costs.std(axis=0)\n",
    "#     ci = 1.96 * std / np.sqrt(10)  # 95% CI\n",
    "#     # Bars with error bars\n",
    "#     plt.bar(trials + i * bar_width - bar_width, mean, width=bar_width, \n",
    "#             color=colors[i], alpha=0.8, label=name, yerr=ci, capsize=2, error_kw={\"ecolor\": \"black\"})\n",
    "#     # Interpolated mean line\n",
    "#     plt.plot(trials, mean, color=colors[i], linewidth=1.5)\n",
    "\n",
    "# plt.plot(trials, analytical_max, \"--\", color=\"#7f7f7f\", label=\"Analytical Maximum\", linewidth=1.5)\n",
    "# plt.xlabel(\"Number of Trials\", fontsize=12)\n",
    "# plt.ylabel(\"Cost\", fontsize=12)\n",
    "# plt.xticks(np.arange(0, 20, 5))\n",
    "# plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "# plt.legend(loc=\"upper right\", bbox_to_anchor=(1.15, 1), fontsize=10)\n",
    "# plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-cpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
